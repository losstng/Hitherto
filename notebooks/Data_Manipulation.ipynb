{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ddacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ec083",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple = (\"left\", 44.44, \"temp\", 99.99)\n",
    "print(tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9100\\2853018828.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  newsletter_df = pd.read_sql_query(\"SELECT * FROM newsletter\", conn)\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(   \n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Fred3001!\",\n",
    "    port=\"5432\")\n",
    "\n",
    "newsletter_df = pd.read_sql_query(\"SELECT * FROM newsletter\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c78e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter_df = newsletter_df.sort_values(by='received_at', ascending=False)\n",
    "newsletter_df = newsletter_df.drop(columns=['id','sender','extracted_text', 'message_id', 'token_count', 'vectorized', 'created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaae4d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>received_at</th>\n",
       "      <th>chunked_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>UBS's profit beats</td>\n",
       "      <td>morning_briefing:_europe</td>\n",
       "      <td>2025-07-30 07:33:39</td>\n",
       "      <td>[Morning Briefing: Europe \\n Bloomberg Morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Breaking News: Japan Issues Tsunami Warning fo...</td>\n",
       "      <td>bloomberg_news_alert</td>\n",
       "      <td>2025-07-30 03:15:53</td>\n",
       "      <td>[Bloomberg News Alert \\n\\n\\n \\n\\n Japan Issues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Money Stuff: UBS FX Trades Were Too Good</td>\n",
       "      <td>money_stuff</td>\n",
       "      <td>2025-07-29 20:13:50</td>\n",
       "      <td>[Money Stuff \\n FX, Sinovac, Daily Journal, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Industrial action</td>\n",
       "      <td>bloomberg_deals</td>\n",
       "      <td>2025-07-29 19:44:32</td>\n",
       "      <td>[Bloomberg Deals \\n Plus: Iveco nears deals wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Harsh reality</td>\n",
       "      <td>evening_briefing:_europe</td>\n",
       "      <td>2025-07-29 18:37:08</td>\n",
       "      <td>[Evening Briefing: Europe \\n Evening Briefing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Economics Daily: ‘Stockholm syndrome’</td>\n",
       "      <td>economics_daily</td>\n",
       "      <td>2025-07-29 13:06:38</td>\n",
       "      <td>[Economics Daily \\n I’m Chris Anstey, an econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Sony's anime music goes platinum</td>\n",
       "      <td>tech_in_depth</td>\n",
       "      <td>2025-07-29 13:04:47</td>\n",
       "      <td>[Tech In Depth \\n Welcome to Tech In Depth, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Supply Lines: Now for the fine print</td>\n",
       "      <td>supply_lines</td>\n",
       "      <td>2025-07-29 13:00:37</td>\n",
       "      <td>[Supply Lines \\n It took less than 48 hours af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Reiches Sommertour mit Tücken: Fünf Themen des...</td>\n",
       "      <td>five_things:_germany</td>\n",
       "      <td>2025-07-29 12:41:27</td>\n",
       "      <td>[Five Things: Germany \\n Nick Heubeck über get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Preventing lip cancer</td>\n",
       "      <td>prognosis</td>\n",
       "      <td>2025-07-29 12:00:48</td>\n",
       "      <td>[Prognosis \\n Where your skin is so thin. \\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "183                                 UBS's profit beats   \n",
       "311  Breaking News: Japan Issues Tsunami Warning fo...   \n",
       "192           Money Stuff: UBS FX Trades Were Too Good   \n",
       "193                                  Industrial action   \n",
       "194                                      Harsh reality   \n",
       "131              Economics Daily: ‘Stockholm syndrome’   \n",
       "134                   Sony's anime music goes platinum   \n",
       "77                Supply Lines: Now for the fine print   \n",
       "78   Reiches Sommertour mit Tücken: Fünf Themen des...   \n",
       "79                               Preventing lip cancer   \n",
       "\n",
       "                     category         received_at  \\\n",
       "183  morning_briefing:_europe 2025-07-30 07:33:39   \n",
       "311      bloomberg_news_alert 2025-07-30 03:15:53   \n",
       "192               money_stuff 2025-07-29 20:13:50   \n",
       "193           bloomberg_deals 2025-07-29 19:44:32   \n",
       "194  evening_briefing:_europe 2025-07-29 18:37:08   \n",
       "131           economics_daily 2025-07-29 13:06:38   \n",
       "134             tech_in_depth 2025-07-29 13:04:47   \n",
       "77               supply_lines 2025-07-29 13:00:37   \n",
       "78       five_things:_germany 2025-07-29 12:41:27   \n",
       "79                  prognosis 2025-07-29 12:00:48   \n",
       "\n",
       "                                          chunked_text  \n",
       "183  [Morning Briefing: Europe \\n Bloomberg Morning...  \n",
       "311  [Bloomberg News Alert \\n\\n\\n \\n\\n Japan Issues...  \n",
       "192  [Money Stuff \\n FX, Sinovac, Daily Journal, in...  \n",
       "193  [Bloomberg Deals \\n Plus: Iveco nears deals wi...  \n",
       "194  [Evening Briefing: Europe \\n Evening Briefing ...  \n",
       "131  [Economics Daily \\n I’m Chris Anstey, an econo...  \n",
       "134  [Tech In Depth \\n Welcome to Tech In Depth, ou...  \n",
       "77   [Supply Lines \\n It took less than 48 hours af...  \n",
       "78   [Five Things: Germany \\n Nick Heubeck über get...  \n",
       "79   [Prognosis \\n Where your skin is so thin. \\n\\n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsletter_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92842e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching NVDA from 2025-08-02 to 2025-08-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NVDA: possibly delisted; no price data found  (1m 2025-08-02 -> 2025-08-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new data returned for NVDA.\n",
      "Fetching INOD from 2025-08-02 to 2025-08-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$INOD: possibly delisted; no price data found  (1m 2025-08-02 -> 2025-08-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new data returned for INOD.\n",
      "Fetching MRVL from 2025-08-02 to 2025-08-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MRVL: possibly delisted; no price data found  (1m 2025-08-02 -> 2025-08-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new data returned for MRVL.\n",
      "Fetching TSLA from 2025-08-02 to 2025-08-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TSLA: possibly delisted; no price data found  (1m 2025-08-02 -> 2025-08-10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new data returned for TSLA.\n",
      "Fetching NVDA daily data from 2025-08-02 to 2025-08-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Documents\\GitHub\\Hitherto\\Scripts\\data.py:100: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  merged_df = pd.concat([old_df, df], sort=False)\n",
      "c:\\Users\\Admin\\Documents\\GitHub\\Hitherto\\Scripts\\data.py:100: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  merged_df = pd.concat([old_df, df], sort=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for NVDA saved to daily_NVDA.csv.\n",
      "Fetching INOD daily data from 2025-08-02 to 2025-08-10...\n",
      "Data for INOD saved to daily_INOD.csv.\n",
      "Fetching MRVL daily data from 2025-08-02 to 2025-08-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Documents\\GitHub\\Hitherto\\Scripts\\data.py:100: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  merged_df = pd.concat([old_df, df], sort=False)\n",
      "c:\\Users\\Admin\\Documents\\GitHub\\Hitherto\\Scripts\\data.py:100: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  merged_df = pd.concat([old_df, df], sort=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for MRVL saved to daily_MRVL.csv.\n",
      "Fetching TSLA daily data from 2025-08-02 to 2025-08-10...\n",
      "Data for TSLA saved to daily_TSLA.csv.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "\n",
    "REPO_ROOT = Path.cwd().parents[0]  # going back once from the current directory\n",
    "SCRIPT_PATH = REPO_ROOT / \"Scripts\"\n",
    "sys.path.append(str(SCRIPT_PATH))\n",
    "from data import update_intraday_csv, update_daily_csv\n",
    "\n",
    "update_intraday_csv(\"NVDA\")\n",
    "update_intraday_csv(\"INOD\")\n",
    "update_intraday_csv(\"MRVL\")\n",
    "update_intraday_csv(\"TSLA\")\n",
    "\n",
    "update_daily_csv(\"NVDA\")\n",
    "update_daily_csv(\"INOD\")\n",
    "update_daily_csv(\"MRVL\")\n",
    "update_daily_csv(\"TSLA\")\n",
    "\n",
    "intraday_nvd = pd.read_csv('..\\\\raw_data\\\\intraday\\\\intraday_NVDA.csv')\n",
    "intraday_mrvl = pd.read_csv('..\\\\raw_data\\\\intraday\\\\intraday_MRVL.csv')\n",
    "intraday_inod = pd.read_csv('..\\\\raw_data\\\\intraday\\\\intraday_INOD.csv')\n",
    "intraday_tsla = pd.read_csv('..\\\\raw_data\\\\intraday\\\\intraday_TSLA.csv')\n",
    "\n",
    "daily_nvd = pd.read_csv('..\\\\raw_data\\\\daily_NVDA.csv')\n",
    "daily_mrvl = pd.read_csv('..\\\\raw_data\\\\daily_MRVL.csv')\n",
    "daily_inod = pd.read_csv('..\\\\raw_data\\\\daily_INOD.csv')\n",
    "daily_tsla = pd.read_csv('..\\\\raw_data\\\\daily_TSLA.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704302a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date       Open       High        Low      Close  \\\n",
      "0  2025-07-01 00:00:00-04:00  50.099998  50.860001  46.299999  47.389999   \n",
      "1  2025-07-02 00:00:00-04:00  46.509998  48.549999  46.150002  47.939999   \n",
      "2  2025-07-03 00:00:00-04:00  48.500000  50.709999  48.470001  50.130001   \n",
      "3  2025-07-07 00:00:00-04:00  48.889999  51.340000  47.810001  50.990002   \n",
      "4  2025-07-08 00:00:00-04:00  51.730000  55.689999  49.750000  50.970001   \n",
      "5  2025-07-09 00:00:00-04:00  51.689999  52.580002  49.410000  52.040001   \n",
      "6  2025-07-10 00:00:00-04:00  53.130001  53.860001  50.470001  52.700001   \n",
      "7  2025-07-11 00:00:00-04:00  52.000000  52.660000  49.290001  49.720001   \n",
      "8  2025-07-14 00:00:00-04:00  49.430000  50.580002  47.320000  50.340000   \n",
      "9  2025-07-15 00:00:00-04:00  50.880001  51.500000  48.369999  49.099998   \n",
      "\n",
      "    Volume  Dividends  Stock Splits  \n",
      "0  2774900        0.0           0.0  \n",
      "1  2516200        0.0           0.0  \n",
      "2  1526300        0.0           0.0  \n",
      "3  1733600        0.0           0.0  \n",
      "4  2922400        0.0           0.0  \n",
      "5  1640700        0.0           0.0  \n",
      "6  1633900        0.0           0.0  \n",
      "7  1630100        0.0           0.0  \n",
      "8  1754500        0.0           0.0  \n",
      "9  1651800        0.0           0.0  \n",
      "                    Datetime       Open       High        Low      Close  \\\n",
      "0  2025-06-23 09:30:00-04:00  46.915001  47.129700  46.630001  46.959999   \n",
      "1  2025-06-23 09:31:00-04:00  46.799999  46.799999  46.119701  46.330002   \n",
      "2  2025-06-23 09:32:00-04:00  46.200001  46.200001  44.520500  44.660000   \n",
      "3  2025-06-23 09:33:00-04:00  44.660000  44.930698  44.340000  44.801201   \n",
      "4  2025-06-23 09:34:00-04:00  44.500000  44.918201  44.340000  44.860001   \n",
      "5  2025-06-23 09:35:00-04:00  44.806599  44.915001  44.000000  44.074299   \n",
      "6  2025-06-23 09:36:00-04:00  44.040001  44.641399  44.000000  44.520000   \n",
      "7  2025-06-23 09:37:00-04:00  44.580002  44.900002  44.435001  44.830002   \n",
      "8  2025-06-23 09:38:00-04:00  44.910000  44.977600  44.740002  44.904999   \n",
      "9  2025-06-23 09:39:00-04:00  44.929401  45.310001  44.810001  45.279999   \n",
      "\n",
      "   Volume  Dividends  Stock Splits  \n",
      "0  335388        0.0           0.0  \n",
      "1   58983        0.0           0.0  \n",
      "2   60705        0.0           0.0  \n",
      "3  233020        0.0           0.0  \n",
      "4   71585        0.0           0.0  \n",
      "5   86815        0.0           0.0  \n",
      "6   36101        0.0           0.0  \n",
      "7   34662        0.0           0.0  \n",
      "8   58491        0.0           0.0  \n",
      "9   27922        0.0           0.0  \n",
      "                                                 title  \\\n",
      "183                                 UBS's profit beats   \n",
      "311  Breaking News: Japan Issues Tsunami Warning fo...   \n",
      "192           Money Stuff: UBS FX Trades Were Too Good   \n",
      "193                                  Industrial action   \n",
      "194                                      Harsh reality   \n",
      "131              Economics Daily: ‘Stockholm syndrome’   \n",
      "134                   Sony's anime music goes platinum   \n",
      "77                Supply Lines: Now for the fine print   \n",
      "78   Reiches Sommertour mit Tücken: Fünf Themen des...   \n",
      "79                               Preventing lip cancer   \n",
      "\n",
      "                     category         received_at  \\\n",
      "183  morning_briefing:_europe 2025-07-30 07:33:39   \n",
      "311      bloomberg_news_alert 2025-07-30 03:15:53   \n",
      "192               money_stuff 2025-07-29 20:13:50   \n",
      "193           bloomberg_deals 2025-07-29 19:44:32   \n",
      "194  evening_briefing:_europe 2025-07-29 18:37:08   \n",
      "131           economics_daily 2025-07-29 13:06:38   \n",
      "134             tech_in_depth 2025-07-29 13:04:47   \n",
      "77               supply_lines 2025-07-29 13:00:37   \n",
      "78       five_things:_germany 2025-07-29 12:41:27   \n",
      "79                  prognosis 2025-07-29 12:00:48   \n",
      "\n",
      "                                          chunked_text  \n",
      "183  [Morning Briefing: Europe \\n Bloomberg Morning...  \n",
      "311  [Bloomberg News Alert \\n\\n\\n \\n\\n Japan Issues...  \n",
      "192  [Money Stuff \\n FX, Sinovac, Daily Journal, in...  \n",
      "193  [Bloomberg Deals \\n Plus: Iveco nears deals wi...  \n",
      "194  [Evening Briefing: Europe \\n Evening Briefing ...  \n",
      "131  [Economics Daily \\n I’m Chris Anstey, an econo...  \n",
      "134  [Tech In Depth \\n Welcome to Tech In Depth, ou...  \n",
      "77   [Supply Lines \\n It took less than 48 hours af...  \n",
      "78   [Five Things: Germany \\n Nick Heubeck über get...  \n",
      "79   [Prognosis \\n Where your skin is so thin. \\n\\n...  \n"
     ]
    }
   ],
   "source": [
    "print(daily_inod.head(10))\n",
    "print(intraday_inod.head(10))\n",
    "print(newsletter_df.head(10))\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "\n",
    "def clean_daily_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the daily data DataFrame by removing unnecessary columns and\n",
    "    converting timezone from US/Eastern to Europe/Berlin.\n",
    "    \"\"\"\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    if df['Date'].dt.tz is None:\n",
    "        df['Date'] = df['Date'].dt.tz_localize('US/Eastern')\n",
    "    df['Date'] = df['Date'].dt.tz_convert('Europe/Berlin')\n",
    "    df = df.drop(columns=['Volume', 'Dividends', 'Stock Splits'])\n",
    "    return df\n",
    "\n",
    "def clean_intraday_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the intraday data DataFrame by removing unnecessary columns, renaming others,\n",
    "    and converting timezone from US/Eastern to Europe/Berlin.\n",
    "    \"\"\"\n",
    "    # Ensure datetime is parsed\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "    # If tz-naive, localize to US/Eastern; then convert to Europe/Berlin\n",
    "    if df['Datetime'].dt.tz is None:\n",
    "        df['Datetime'] = df['Datetime'].dt.tz_localize('US/Eastern')\n",
    "    df['Datetime'] = df['Datetime'].dt.tz_convert('Europe/Berlin')\n",
    "\n",
    "    # Extract components **after** timezone conversion\n",
    "    df['Date'] = df['Datetime'].dt.date\n",
    "    df['Time'] = df['Datetime'].dt.time\n",
    "    df['Hour'] = df['Datetime'].dt.hour\n",
    "    df['Minute'] = df['Datetime'].dt.minute\n",
    "\n",
    "    # Drop unneeded columns if they exist\n",
    "    for col in ['Dividends', 'Stock Splits']:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=col)\n",
    "    df = df.drop(columns=['Datetime'])\n",
    "    return df\n",
    "\n",
    "intraday_inod = clean_intraday_data(intraday_inod)\n",
    "intraday_mrvl = clean_intraday_data(intraday_mrvl)\n",
    "intraday_nvd = clean_intraday_data(intraday_nvd)\n",
    "intraday_tsla = clean_intraday_data(intraday_tsla)\n",
    "\n",
    "daily_inod = clean_daily_data(daily_inod)\n",
    "daily_mrvl = clean_daily_data(daily_mrvl)\n",
    "daily_nvd = clean_daily_data(daily_nvd)\n",
    "daily_tsla = clean_daily_data(daily_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fe9750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date       Open       High        Low      Close\n",
      "0 2025-07-01 06:00:00+02:00  50.099998  50.860001  46.299999  47.389999\n",
      "        Open     High        Low      Close  Volume        Date      Time  \\\n",
      "0  46.915001  47.1297  46.630001  46.959999  335388  2025-06-23  15:30:00   \n",
      "\n",
      "   Hour  Minute  \n",
      "0    15      30  \n",
      "                  title                  category         received_at  \\\n",
      "183  UBS's profit beats  morning_briefing:_europe 2025-07-30 07:33:39   \n",
      "\n",
      "                                          chunked_text  \n",
      "183  [Morning Briefing: Europe \\n Bloomberg Morning...  \n"
     ]
    }
   ],
   "source": [
    "print(daily_inod.head(1))\n",
    "print(intraday_inod.head(1))\n",
    "print(newsletter_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "def add_returns_to_entries(entries_df, daily_ohlc_df,\n",
    "                           entry_date_col='received_at',\n",
    "                           price_date_col='Date',\n",
    "                           return_days=[1, 3]):\n",
    "    \"\"\"\n",
    "    Adds future returns to an entries dataframe based on close prices in daily OHLC data.\n",
    "    Can use either OHLC-derived or exchange-trading-calendar-based trading day logic.\n",
    "    Toggle between the two by commenting/uncommenting the appropriate trading_days section.\n",
    "    \"\"\"\n",
    "    entries_df = entries_df.copy()\n",
    "    daily_ohlc_df = daily_ohlc_df.copy()\n",
    "\n",
    "    # Normalize to timezone-naive date\n",
    "    entries_df['entry_date'] = pd.to_datetime(entries_df[entry_date_col], errors='coerce').dt.date\n",
    "    daily_ohlc_df['price_date'] = pd.to_datetime(daily_ohlc_df[price_date_col], errors='coerce').dt.tz_localize(None).dt.date\n",
    "\n",
    "    # Map close prices\n",
    "    close_price_map = daily_ohlc_df.set_index('price_date')['Close'].to_dict()\n",
    "\n",
    "    # === TRADING DAYS SETUP ===\n",
    "\n",
    "    # METHOD 1: Use OHLC-derived trading days (original logic)\n",
    "    trading_days = sorted(daily_ohlc_df['price_date'].dropna().unique())\n",
    "\n",
    "    # METHOD 2: Use official exchange trading calendar (uncomment to use)\n",
    "    # calendar = mcal.get_calendar('NYSE')\n",
    "    # trading_days = calendar.valid_days(\n",
    "    #     start_date=min(daily_ohlc_df['price_date']),\n",
    "    #     end_date=max(daily_ohlc_df['price_date'])\n",
    "    # ).date\n",
    "\n",
    "    # ============================\n",
    "\n",
    "    # Efficient trading day lookup\n",
    "    def get_t_plus_n(entry_date, n):\n",
    "        if pd.isnull(entry_date):\n",
    "            return None\n",
    "        try:\n",
    "            idx = trading_days.index(entry_date)\n",
    "            if idx + n < len(trading_days):\n",
    "                return trading_days[idx + n]\n",
    "            else:\n",
    "                return None  # No future price available\n",
    "        except ValueError:\n",
    "            return None  # entry_date not in trading_days\n",
    "\n",
    "    for n in return_days:\n",
    "        t_col = f't_plus_{n}'\n",
    "        ret_col = f'{n}d_return'\n",
    "\n",
    "        # Map T+n date\n",
    "        entries_df[t_col] = entries_df['entry_date'].apply(lambda x: get_t_plus_n(x, n))\n",
    "\n",
    "        # Calculate return\n",
    "        def calc_return(row):\n",
    "            try:\n",
    "                p0 = close_price_map.get(row['entry_date'])\n",
    "                pn = close_price_map.get(row[t_col])\n",
    "                if p0 is None or pn is None:\n",
    "                    return None\n",
    "                return (pn - p0) / p0\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        entries_df[ret_col] = entries_df.apply(calc_return, axis=1)\n",
    "\n",
    "    return entries_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b060d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title  \\\n",
      "79                               Preventing lip cancer   \n",
      "78   Reiches Sommertour mit Tücken: Fünf Themen des...   \n",
      "77                Supply Lines: Now for the fine print   \n",
      "134                   Sony's anime music goes platinum   \n",
      "131              Economics Daily: ‘Stockholm syndrome’   \n",
      "194                                      Harsh reality   \n",
      "193                                  Industrial action   \n",
      "192           Money Stuff: UBS FX Trades Were Too Good   \n",
      "311  Breaking News: Japan Issues Tsunami Warning fo...   \n",
      "183                                 UBS's profit beats   \n",
      "\n",
      "                     category         received_at  \\\n",
      "79                  prognosis 2025-07-29 12:00:48   \n",
      "78       five_things:_germany 2025-07-29 12:41:27   \n",
      "77               supply_lines 2025-07-29 13:00:37   \n",
      "134             tech_in_depth 2025-07-29 13:04:47   \n",
      "131           economics_daily 2025-07-29 13:06:38   \n",
      "194  evening_briefing:_europe 2025-07-29 18:37:08   \n",
      "193           bloomberg_deals 2025-07-29 19:44:32   \n",
      "192               money_stuff 2025-07-29 20:13:50   \n",
      "311      bloomberg_news_alert 2025-07-30 03:15:53   \n",
      "183  morning_briefing:_europe 2025-07-30 07:33:39   \n",
      "\n",
      "                                          chunked_text  entry_date  \\\n",
      "79   [Prognosis \\n Where your skin is so thin. \\n\\n...  2025-07-29   \n",
      "78   [Five Things: Germany \\n Nick Heubeck über get...  2025-07-29   \n",
      "77   [Supply Lines \\n It took less than 48 hours af...  2025-07-29   \n",
      "134  [Tech In Depth \\n Welcome to Tech In Depth, ou...  2025-07-29   \n",
      "131  [Economics Daily \\n I’m Chris Anstey, an econo...  2025-07-29   \n",
      "194  [Evening Briefing: Europe \\n Evening Briefing ...  2025-07-29   \n",
      "193  [Bloomberg Deals \\n Plus: Iveco nears deals wi...  2025-07-29   \n",
      "192  [Money Stuff \\n FX, Sinovac, Daily Journal, in...  2025-07-29   \n",
      "311  [Bloomberg News Alert \\n\\n\\n \\n\\n Japan Issues...  2025-07-30   \n",
      "183  [Morning Briefing: Europe \\n Bloomberg Morning...  2025-07-30   \n",
      "\n",
      "       t_plus_1  1d_return    t_plus_3  3d_return  \n",
      "79   2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "78   2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "77   2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "134  2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "131  2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "194  2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "193  2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "192  2025-07-30   0.026461  2025-08-01  -0.048264  \n",
      "311  2025-07-31   0.114044        None        NaN  \n",
      "183  2025-07-31   0.114044        None        NaN  \n"
     ]
    }
   ],
   "source": [
    "newsletter_df = add_returns_to_entries(newsletter_df, daily_inod,entry_date_col='received_at', \n",
    "                           price_date_col='Date', \n",
    "                           return_days=[1, 3])\n",
    "\n",
    "print(newsletter_df.head(10).sort_values(by='received_at', ascending=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
